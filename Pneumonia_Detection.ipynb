{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T20:25:00.323280Z",
     "start_time": "2024-09-27T18:42:29.648080Z"
    }
   },
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.25  # Increased validation split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/gagan/Desktop/University /chest_xray/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/gagan/Desktop/University /chest_xray/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers initially\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Calculate dynamic class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Callbacks\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[lr_reduce, early_stop],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Fine-tuning: Unfreeze the last 50 layers of the base model\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model for additional epochs\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[lr_reduce, early_stop],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('/Users/gagan/Desktop/University/pneumonia_detection_resnet50_optimized_3.h5')\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "validation_generator.reset()\n",
    "preds = model.predict(validation_generator)\n",
    "preds = preds.flatten()\n",
    "\n",
    "# ROC Curve analysis to find the optimal threshold\n",
    "fpr, tpr, thresholds = roc_curve(validation_generator.classes, preds)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "preds_optimal = (preds > optimal_threshold).astype(int)\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(classification_report(validation_generator.classes, preds_optimal, target_names=['Normal', 'Pneumonia']))\n",
    "print(confusion_matrix(validation_generator.classes, preds_optimal))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3913 images belonging to 2 classes.\n",
      "Found 1303 images belonging to 2 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagan/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m146s\u001B[0m 1s/step - accuracy: 0.5052 - loss: 0.7552 - val_accuracy: 0.7460 - val_loss: 0.5968 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m150s\u001B[0m 1s/step - accuracy: 0.5865 - loss: 0.6805 - val_accuracy: 0.7421 - val_loss: 0.6175 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m152s\u001B[0m 1s/step - accuracy: 0.6734 - loss: 0.6170 - val_accuracy: 0.6025 - val_loss: 0.6830 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 923ms/step - accuracy: 0.6979 - loss: 0.5938\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m156s\u001B[0m 1s/step - accuracy: 0.6978 - loss: 0.5939 - val_accuracy: 0.7229 - val_loss: 0.6308 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m162s\u001B[0m 1s/step - accuracy: 0.7229 - loss: 0.5793 - val_accuracy: 0.7176 - val_loss: 0.5992 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m162s\u001B[0m 1s/step - accuracy: 0.7146 - loss: 0.5857 - val_accuracy: 0.7444 - val_loss: 0.5688 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m163s\u001B[0m 1s/step - accuracy: 0.7361 - loss: 0.5769 - val_accuracy: 0.7007 - val_loss: 0.6298 - learning_rate: 1.0000e-05\n",
      "Epoch 8/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m164s\u001B[0m 1s/step - accuracy: 0.7373 - loss: 0.5675 - val_accuracy: 0.7352 - val_loss: 0.6041 - learning_rate: 1.0000e-05\n",
      "Epoch 9/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1s/step - accuracy: 0.7345 - loss: 0.5712\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 1s/step - accuracy: 0.7345 - loss: 0.5712 - val_accuracy: 0.7260 - val_loss: 0.6016 - learning_rate: 1.0000e-05\n",
      "Epoch 10/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m172s\u001B[0m 1s/step - accuracy: 0.7321 - loss: 0.5788 - val_accuracy: 0.7145 - val_loss: 0.6054 - learning_rate: 1.0000e-06\n",
      "Epoch 11/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m173s\u001B[0m 1s/step - accuracy: 0.7555 - loss: 0.5655 - val_accuracy: 0.7160 - val_loss: 0.6039 - learning_rate: 1.0000e-06\n",
      "Epoch 12/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1s/step - accuracy: 0.7440 - loss: 0.5585\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m174s\u001B[0m 1s/step - accuracy: 0.7440 - loss: 0.5585 - val_accuracy: 0.7337 - val_loss: 0.6033 - learning_rate: 1.0000e-06\n",
      "Epoch 13/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m174s\u001B[0m 1s/step - accuracy: 0.7432 - loss: 0.5663 - val_accuracy: 0.7306 - val_loss: 0.6023 - learning_rate: 1.0000e-07\n",
      "Epoch 1/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m271s\u001B[0m 2s/step - accuracy: 0.7412 - loss: 0.6520 - val_accuracy: 0.7414 - val_loss: 0.4959 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m270s\u001B[0m 2s/step - accuracy: 0.8064 - loss: 0.4427 - val_accuracy: 0.7598 - val_loss: 0.4758 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m267s\u001B[0m 2s/step - accuracy: 0.8266 - loss: 0.3839 - val_accuracy: 0.8258 - val_loss: 0.3899 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m269s\u001B[0m 2s/step - accuracy: 0.8406 - loss: 0.3715 - val_accuracy: 0.8304 - val_loss: 0.3702 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m263s\u001B[0m 2s/step - accuracy: 0.8377 - loss: 0.3411 - val_accuracy: 0.8196 - val_loss: 0.3748 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m266s\u001B[0m 2s/step - accuracy: 0.8472 - loss: 0.3190 - val_accuracy: 0.8373 - val_loss: 0.3530 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m264s\u001B[0m 2s/step - accuracy: 0.8485 - loss: 0.3291 - val_accuracy: 0.8227 - val_loss: 0.3915 - learning_rate: 1.0000e-06\n",
      "Epoch 8/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m265s\u001B[0m 2s/step - accuracy: 0.8483 - loss: 0.3175 - val_accuracy: 0.8757 - val_loss: 0.2804 - learning_rate: 1.0000e-06\n",
      "Epoch 9/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m265s\u001B[0m 2s/step - accuracy: 0.8609 - loss: 0.3036 - val_accuracy: 0.8488 - val_loss: 0.3236 - learning_rate: 1.0000e-06\n",
      "Epoch 10/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m265s\u001B[0m 2s/step - accuracy: 0.8645 - loss: 0.2915 - val_accuracy: 0.8573 - val_loss: 0.3244 - learning_rate: 1.0000e-06\n",
      "Epoch 11/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.8674 - loss: 0.3036\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m261s\u001B[0m 2s/step - accuracy: 0.8674 - loss: 0.3035 - val_accuracy: 0.7913 - val_loss: 0.4523 - learning_rate: 1.0000e-06\n",
      "Epoch 12/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m262s\u001B[0m 2s/step - accuracy: 0.8588 - loss: 0.3100 - val_accuracy: 0.8442 - val_loss: 0.3542 - learning_rate: 1.0000e-07\n",
      "Epoch 13/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m261s\u001B[0m 2s/step - accuracy: 0.8583 - loss: 0.3035 - val_accuracy: 0.8534 - val_loss: 0.3062 - learning_rate: 1.0000e-07\n",
      "Epoch 14/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.8764 - loss: 0.2761\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m268s\u001B[0m 2s/step - accuracy: 0.8763 - loss: 0.2762 - val_accuracy: 0.8289 - val_loss: 0.3748 - learning_rate: 1.0000e-07\n",
      "Epoch 15/50\n",
      "\u001B[1m123/123\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m265s\u001B[0m 2s/step - accuracy: 0.8643 - loss: 0.2960 - val_accuracy: 0.8419 - val_loss: 0.3479 - learning_rate: 1.0000e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m41/41\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.26      0.91      0.40       335\n",
      "   Pneumonia       0.77      0.11      0.19       968\n",
      "\n",
      "    accuracy                           0.31      1303\n",
      "   macro avg       0.51      0.51      0.29      1303\n",
      "weighted avg       0.64      0.31      0.24      1303\n",
      "\n",
      "[[304  31]\n",
      " [866 102]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T16:09:01.238225Z",
     "start_time": "2024-09-29T16:08:24.529753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Path to the dataset directories\n",
    "test_dir ='/Users/gagan/Desktop/University /chest_xray/test'\n",
    "# Load your model\n",
    "model = load_model('/Users/gagan/Desktop/University/Final submit/pneumonia_detection_resnet50_optimized_3.h5')\n",
    "\n",
    "# Set up data augmentation and preprocessing for the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),  # Ensure this matches your model's input size\n",
    "    batch_size=16,\n",
    "    class_mode='binary',  # Binary classification since you only have two classes\n",
    "    shuffle=False  # Do not shuffle the test set\n",
    ")\n",
    "\n",
    "# Compile the model with binary crossentropy and appropriate metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Binary crossentropy for binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = (predictions > 0.5).astype(\"int32\").flatten()  # Convert probabilities to binary class predictions\n",
    "\n",
    "# True labels\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optional: Apply ReduceLROnPlateau to improve training (if you retrain the model)\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "# Example for retraining (adjust according to your training setup)\n",
    "# model.fit(train_generator, validation_data=validation_generator, epochs=10, class_weight=class_weights_dict, callbacks=[reduce_lr])"
   ],
   "id": "2402c09aee0f04d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gagan/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 433ms/step - accuracy: 0.8307 - loss: 0.4874\n",
      "Test Loss: 0.399677574634552\n",
      "Test Accuracy: 0.8445512652397156\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 433ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.79      0.79      0.79       234\n",
      "   PNEUMONIA       0.87      0.88      0.88       390\n",
      "\n",
      "    accuracy                           0.84       624\n",
      "   macro avg       0.83      0.83      0.83       624\n",
      "weighted avg       0.84      0.84      0.84       624\n",
      "\n",
      "Confusion Matrix:\n",
      "[[185  49]\n",
      " [ 48 342]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f901a3835eb25528"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
